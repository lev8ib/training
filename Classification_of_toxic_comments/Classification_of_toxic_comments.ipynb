{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проект с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Содержание проекта\n",
    "\n",
    "<a href='#step1'>1.Подготовка</a>\n",
    "\n",
    "<a href='#step2'>2.Обучение</a>\n",
    "\n",
    "<a href='#step3'>3.Вывод</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка <a id='step1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import notebook\n",
    "import torch\n",
    "import transformers as ppb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и осмотрим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевого признака, построив гистограмму и подсчитав уникальные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'распределение целевого признака')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['toxic'].hist(color = \"g\");\n",
    "plt.title('распределение целевого признака')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присутствует дисбаланс в целевом признаке. Количество токсичных комментариев значительно меньше. Необходимо это учеть при обучении моделей.\n",
    "\n",
    "Прежде чем извлечь признаки из текста, упростим его.\n",
    "Воспользуемся Лемматизацией — приведение слова к начальной форме (лемме).\n",
    "Применим лемматизатор Wordnet из NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы найти правильный POS-тег для каждого слова, сопоставим его с правильным входным символом, который принимает WordnetLemmatizer, и передадим его в качестве второго аргумента в lemmatize().\n",
    "В nltk для этого есть метод nltk.pos_tag(). Он принимает список слов, а возвращает кортеж с тегом POS. Ключевым моментом здесь является сопоставление POS-тегов NLTK с форматом, принятым лемматизатором wordnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся готовыми и напишем функции для лемматизации текста:\n",
    "get_wordnet_pos(word) - возвращает POS тэг для слова(к какой части речи относится слово)\n",
    "clear_text(text) - приводит к нижнему регистру и очишает от символом, кроме букв английского алфавита(через re)\n",
    "lemmatize(text) - проводит лемматизацию текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_list = nltk.word_tokenize(text)\n",
    "    lemm_text = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lemm_list])      \n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    clear_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clear_text = clear_text.lower().split()\n",
    "    return ' '.join(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что функции работают корректно на тексте первой строке обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits make under my username hardcore metallica fan be revert they weren t vandalism just closure on some gas after i vote at new york doll fac and please don t remove the template from the talk page since i m retire now'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(clear_text(df.loc[0, 'text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем лемматизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 22s, sys: 2min 57s, total: 38min 19s\n",
      "Wall time: 38min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemm_text'] = df['text'].apply(lambda text: lemmatize(clear_text(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='toxic', data=df, palette='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы сохранить результаты лемматизации и не запускать снова трудоемкий процесс, сохраним в csv и будем использовать его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lemm_toxic_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lemm_toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датафрейм на 2 части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    df['lemm_text'], df['toxic'], test_size=0.25, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем размеры матриц и векторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119678,), (39893,), (119678,), (39893,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape, train_target.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпуса слов для обучающей и тестовой выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = train_features.values.astype('U')\n",
    "test_corpus = test_features.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы почистить мешок слов, найдём стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычислим TF-IDF для корпуса текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитать TF-IDF можно и в библиотеке sklearn. Класс TfidfVectorizer() в модуле sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "train_tf_idf = count_tf_idf.fit_transform(train_corpus)\n",
    "test_tf_idf = count_tf_idf.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем размеры получившихся матриц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей матрицы: (119678, 128432)\n",
      "Размер тестовой матрицы: (39893, 128432)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер обучающей матрицы:\", train_tf_idf.shape), \n",
    "print(\"Размер тестовой матрицы:\", test_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию scoring(fitted_model) для определения метрики f1_score для тестовой выбороки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(fitted_model):\n",
    "    test_pred = fitted_model.predict(test_tf_idf)\n",
    "    test_f1 = f1_score(test_target, test_pred)\n",
    "    \n",
    "    print('F1 на тестовой выборке: {:.3f}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "В процессе загрузки и обработки данных обнаружены следующие факты\n",
    "\n",
    "В данных присутствовал дисбаланс целевого признака\n",
    "NLTK библиотека позволила преобразоваться тексты в векторный вид, пригодный для обучения моделей.\n",
    "TF-IDF существенно увеличил количество признаков, равное количеству в мешке слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение  <a id='step1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим несколько моделей и оценим полученные результаты.\n",
    "Модели для обучения:\n",
    "\n",
    "* LogisticRegression\n",
    "* XGBClassifier\n",
    "* CatBoostClassifier\n",
    "* LGBMClassifier\n",
    "\n",
    "Для подбора гиперпараметров импортируем GridSearchCV, для кросс-валидации при подборе гиперпараметров ShuffleSplit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=2, test_size=0.25, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим логистическую регресиию LogisticRegression как базовую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=17, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_params = {'C': np.linspace(0.0001, 100, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 57s, sys: 8min 6s, total: 17min 3s\n",
      "Wall time: 17min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                          dual=False, fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=17, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000e-04, 1.11112e+01, 2.22223e+01, 3.33334e+01, 4.44445e+01,\n",
       "       5.55556e+01, 6.66667e+01, 7.77778e+01, 8.88889e+01, 1.00000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_grid = GridSearchCV(log_reg, log_reg_params, scoring='f1')\n",
    "log_reg_grid.fit(train_tf_idf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 11.1112}\n",
      "best scores:  0.7575399592857313\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', log_reg_grid.best_params_)\n",
    "print('best scores: ', log_reg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=11.1112, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=17, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.761\n",
      "CPU times: user 24.1 ms, sys: 0 ns, total: 24.1 ms\n",
      "Wall time: 24.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring(log_reg_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим модель градиентного бустинга XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_params = {'n_estimators': [100, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min, sys: 0 ns, total: 54min\n",
      "Wall time: 54min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=-1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=17, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=None, param_grid={'n_estimators': [100, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_clf_grid = GridSearchCV(xgb_clf, xgb_clf_params, scoring='f1')\n",
    "xgb_clf_grid.fit(train_tf_idf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'n_estimators': 500}\n",
      "best scores:  0.7061738769236844\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', xgb_clf_grid.best_params_)\n",
    "print('best scores: ', xgb_clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=500, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=17,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.709\n",
      "CPU times: user 2.76 s, sys: 0 ns, total: 2.76 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring(xgb_clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим модель градиентного бустинга CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86305     0\n",
       "86000     0\n",
       "122621    0\n",
       "150823    0\n",
       "128349    0\n",
       "         ..\n",
       "25631     0\n",
       "125680    0\n",
       "42297     0\n",
       "34959     1\n",
       "64753     0\n",
       "Name: toxic, Length: 119678, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.857"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_pos_weight = round((len(train_target[train_target == 0]) / \n",
    "                          len(train_target[train_target == 1])), 3)\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoost_clf = CatBoostClassifier(random_state=17, iterations=500, scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.120343\n",
      "0:\tlearn: 0.6370528\ttotal: 5.65s\tremaining: 46m 57s\n",
      "1:\tlearn: 0.6007665\ttotal: 10.3s\tremaining: 42m 32s\n",
      "2:\tlearn: 0.5772803\ttotal: 15s\tremaining: 41m 32s\n",
      "3:\tlearn: 0.5614775\ttotal: 19.7s\tremaining: 40m 47s\n",
      "4:\tlearn: 0.5524966\ttotal: 24.2s\tremaining: 40m\n",
      "5:\tlearn: 0.5386061\ttotal: 28.7s\tremaining: 39m 26s\n",
      "6:\tlearn: 0.5299564\ttotal: 33.3s\tremaining: 39m 8s\n",
      "7:\tlearn: 0.5222804\ttotal: 37.9s\tremaining: 38m 53s\n",
      "8:\tlearn: 0.5146054\ttotal: 42.5s\tremaining: 38m 40s\n",
      "9:\tlearn: 0.5048728\ttotal: 46.8s\tremaining: 38m 15s\n",
      "10:\tlearn: 0.4986368\ttotal: 51.4s\tremaining: 38m 6s\n",
      "11:\tlearn: 0.4930663\ttotal: 56s\tremaining: 37m 59s\n",
      "12:\tlearn: 0.4885478\ttotal: 1m\tremaining: 37m 51s\n",
      "13:\tlearn: 0.4829496\ttotal: 1m 5s\tremaining: 37m 41s\n",
      "14:\tlearn: 0.4785651\ttotal: 1m 9s\tremaining: 37m 28s\n",
      "15:\tlearn: 0.4743093\ttotal: 1m 14s\tremaining: 37m 19s\n",
      "16:\tlearn: 0.4699834\ttotal: 1m 18s\tremaining: 37m 11s\n",
      "17:\tlearn: 0.4648785\ttotal: 1m 22s\tremaining: 36m 58s\n",
      "18:\tlearn: 0.4606197\ttotal: 1m 27s\tremaining: 36m 53s\n",
      "19:\tlearn: 0.4581023\ttotal: 1m 31s\tremaining: 36m 44s\n",
      "20:\tlearn: 0.4546433\ttotal: 1m 36s\tremaining: 36m 35s\n",
      "21:\tlearn: 0.4511619\ttotal: 1m 40s\tremaining: 36m 28s\n",
      "22:\tlearn: 0.4489793\ttotal: 1m 45s\tremaining: 36m 20s\n",
      "23:\tlearn: 0.4464133\ttotal: 1m 49s\tremaining: 36m 12s\n",
      "24:\tlearn: 0.4435470\ttotal: 1m 54s\tremaining: 36m 8s\n",
      "25:\tlearn: 0.4411347\ttotal: 1m 58s\tremaining: 35m 59s\n",
      "26:\tlearn: 0.4385910\ttotal: 2m 2s\tremaining: 35m 51s\n",
      "27:\tlearn: 0.4365032\ttotal: 2m 7s\tremaining: 35m 46s\n",
      "28:\tlearn: 0.4340613\ttotal: 2m 11s\tremaining: 35m 37s\n",
      "29:\tlearn: 0.4323968\ttotal: 2m 16s\tremaining: 35m 34s\n",
      "30:\tlearn: 0.4297226\ttotal: 2m 20s\tremaining: 35m 28s\n",
      "31:\tlearn: 0.4281631\ttotal: 2m 25s\tremaining: 35m 22s\n",
      "32:\tlearn: 0.4257064\ttotal: 2m 29s\tremaining: 35m 17s\n",
      "33:\tlearn: 0.4231533\ttotal: 2m 34s\tremaining: 35m 12s\n",
      "34:\tlearn: 0.4214589\ttotal: 2m 38s\tremaining: 35m 7s\n",
      "35:\tlearn: 0.4187817\ttotal: 2m 43s\tremaining: 35m 1s\n",
      "36:\tlearn: 0.4167463\ttotal: 2m 47s\tremaining: 34m 55s\n",
      "37:\tlearn: 0.4153219\ttotal: 2m 51s\tremaining: 34m 50s\n",
      "38:\tlearn: 0.4134960\ttotal: 2m 56s\tremaining: 34m 45s\n",
      "39:\tlearn: 0.4114512\ttotal: 3m 1s\tremaining: 34m 41s\n",
      "40:\tlearn: 0.4101099\ttotal: 3m 5s\tremaining: 34m 38s\n",
      "41:\tlearn: 0.4081210\ttotal: 3m 10s\tremaining: 34m 32s\n",
      "42:\tlearn: 0.4062524\ttotal: 3m 14s\tremaining: 34m 27s\n",
      "43:\tlearn: 0.4049490\ttotal: 3m 18s\tremaining: 34m 21s\n",
      "44:\tlearn: 0.4035242\ttotal: 3m 23s\tremaining: 34m 17s\n",
      "45:\tlearn: 0.4017456\ttotal: 3m 28s\tremaining: 34m 13s\n",
      "46:\tlearn: 0.3990806\ttotal: 3m 32s\tremaining: 34m 9s\n",
      "47:\tlearn: 0.3976491\ttotal: 3m 36s\tremaining: 34m 2s\n",
      "48:\tlearn: 0.3964982\ttotal: 3m 41s\tremaining: 33m 57s\n",
      "49:\tlearn: 0.3945794\ttotal: 3m 45s\tremaining: 33m 52s\n",
      "50:\tlearn: 0.3937530\ttotal: 3m 50s\tremaining: 33m 47s\n",
      "51:\tlearn: 0.3926737\ttotal: 3m 54s\tremaining: 33m 42s\n",
      "52:\tlearn: 0.3917104\ttotal: 3m 59s\tremaining: 33m 38s\n",
      "53:\tlearn: 0.3907248\ttotal: 4m 3s\tremaining: 33m 32s\n",
      "54:\tlearn: 0.3897526\ttotal: 4m 8s\tremaining: 33m 28s\n",
      "55:\tlearn: 0.3884920\ttotal: 4m 12s\tremaining: 33m 24s\n",
      "56:\tlearn: 0.3875327\ttotal: 4m 17s\tremaining: 33m 19s\n",
      "57:\tlearn: 0.3868365\ttotal: 4m 21s\tremaining: 33m 13s\n",
      "58:\tlearn: 0.3858426\ttotal: 4m 25s\tremaining: 33m 8s\n",
      "59:\tlearn: 0.3849535\ttotal: 4m 30s\tremaining: 33m 2s\n",
      "60:\tlearn: 0.3839545\ttotal: 4m 34s\tremaining: 32m 57s\n",
      "61:\tlearn: 0.3825951\ttotal: 4m 39s\tremaining: 32m 52s\n",
      "62:\tlearn: 0.3812644\ttotal: 4m 43s\tremaining: 32m 47s\n",
      "63:\tlearn: 0.3801347\ttotal: 4m 48s\tremaining: 32m 42s\n",
      "64:\tlearn: 0.3789444\ttotal: 4m 52s\tremaining: 32m 37s\n",
      "65:\tlearn: 0.3771918\ttotal: 4m 57s\tremaining: 32m 34s\n",
      "66:\tlearn: 0.3762651\ttotal: 5m 1s\tremaining: 32m 29s\n",
      "67:\tlearn: 0.3752853\ttotal: 5m 6s\tremaining: 32m 24s\n",
      "68:\tlearn: 0.3741530\ttotal: 5m 10s\tremaining: 32m 18s\n",
      "69:\tlearn: 0.3730291\ttotal: 5m 14s\tremaining: 32m 14s\n",
      "70:\tlearn: 0.3716209\ttotal: 5m 19s\tremaining: 32m 9s\n",
      "71:\tlearn: 0.3707474\ttotal: 5m 23s\tremaining: 32m 4s\n",
      "72:\tlearn: 0.3700062\ttotal: 5m 28s\tremaining: 32m\n",
      "73:\tlearn: 0.3691788\ttotal: 5m 32s\tremaining: 31m 55s\n",
      "74:\tlearn: 0.3678345\ttotal: 5m 37s\tremaining: 31m 50s\n",
      "75:\tlearn: 0.3668559\ttotal: 5m 41s\tremaining: 31m 45s\n",
      "76:\tlearn: 0.3659121\ttotal: 5m 45s\tremaining: 31m 40s\n",
      "77:\tlearn: 0.3651620\ttotal: 5m 50s\tremaining: 31m 35s\n",
      "78:\tlearn: 0.3643722\ttotal: 5m 54s\tremaining: 31m 30s\n",
      "79:\tlearn: 0.3629817\ttotal: 5m 59s\tremaining: 31m 25s\n",
      "80:\tlearn: 0.3620533\ttotal: 6m 3s\tremaining: 31m 20s\n",
      "81:\tlearn: 0.3605959\ttotal: 6m 7s\tremaining: 31m 15s\n",
      "82:\tlearn: 0.3598897\ttotal: 6m 12s\tremaining: 31m 9s\n",
      "83:\tlearn: 0.3589303\ttotal: 6m 16s\tremaining: 31m 4s\n",
      "84:\tlearn: 0.3579037\ttotal: 6m 20s\tremaining: 31m\n",
      "85:\tlearn: 0.3572495\ttotal: 6m 25s\tremaining: 30m 55s\n",
      "86:\tlearn: 0.3562567\ttotal: 6m 29s\tremaining: 30m 49s\n",
      "87:\tlearn: 0.3555591\ttotal: 6m 34s\tremaining: 30m 45s\n",
      "88:\tlearn: 0.3548626\ttotal: 6m 38s\tremaining: 30m 39s\n",
      "89:\tlearn: 0.3540449\ttotal: 6m 42s\tremaining: 30m 35s\n",
      "90:\tlearn: 0.3532208\ttotal: 6m 47s\tremaining: 30m 30s\n",
      "91:\tlearn: 0.3522186\ttotal: 6m 51s\tremaining: 30m 25s\n",
      "92:\tlearn: 0.3515223\ttotal: 6m 56s\tremaining: 30m 21s\n",
      "93:\tlearn: 0.3509689\ttotal: 7m\tremaining: 30m 16s\n",
      "94:\tlearn: 0.3502786\ttotal: 7m 4s\tremaining: 30m 11s\n",
      "95:\tlearn: 0.3496334\ttotal: 7m 9s\tremaining: 30m 6s\n",
      "96:\tlearn: 0.3479629\ttotal: 7m 13s\tremaining: 30m 2s\n",
      "97:\tlearn: 0.3471787\ttotal: 7m 18s\tremaining: 29m 57s\n",
      "98:\tlearn: 0.3463737\ttotal: 7m 22s\tremaining: 29m 53s\n",
      "99:\tlearn: 0.3457884\ttotal: 7m 27s\tremaining: 29m 48s\n",
      "100:\tlearn: 0.3449644\ttotal: 7m 31s\tremaining: 29m 43s\n",
      "101:\tlearn: 0.3441580\ttotal: 7m 35s\tremaining: 29m 38s\n",
      "102:\tlearn: 0.3429902\ttotal: 7m 40s\tremaining: 29m 34s\n",
      "103:\tlearn: 0.3423469\ttotal: 7m 44s\tremaining: 29m 29s\n",
      "104:\tlearn: 0.3415997\ttotal: 7m 49s\tremaining: 29m 25s\n",
      "105:\tlearn: 0.3409789\ttotal: 7m 53s\tremaining: 29m 20s\n",
      "106:\tlearn: 0.3402790\ttotal: 7m 58s\tremaining: 29m 15s\n",
      "107:\tlearn: 0.3391640\ttotal: 8m 2s\tremaining: 29m 11s\n",
      "108:\tlearn: 0.3383536\ttotal: 8m 6s\tremaining: 29m 6s\n",
      "109:\tlearn: 0.3376130\ttotal: 8m 11s\tremaining: 29m 2s\n",
      "110:\tlearn: 0.3368378\ttotal: 8m 15s\tremaining: 28m 57s\n",
      "111:\tlearn: 0.3361558\ttotal: 8m 20s\tremaining: 28m 53s\n",
      "112:\tlearn: 0.3353659\ttotal: 8m 24s\tremaining: 28m 49s\n",
      "113:\tlearn: 0.3345728\ttotal: 8m 29s\tremaining: 28m 44s\n",
      "114:\tlearn: 0.3339176\ttotal: 8m 33s\tremaining: 28m 40s\n",
      "115:\tlearn: 0.3332430\ttotal: 8m 38s\tremaining: 28m 35s\n",
      "116:\tlearn: 0.3325477\ttotal: 8m 42s\tremaining: 28m 31s\n",
      "117:\tlearn: 0.3317758\ttotal: 8m 47s\tremaining: 28m 26s\n",
      "118:\tlearn: 0.3311472\ttotal: 8m 51s\tremaining: 28m 21s\n",
      "119:\tlearn: 0.3301045\ttotal: 8m 56s\tremaining: 28m 17s\n",
      "120:\tlearn: 0.3294555\ttotal: 9m\tremaining: 28m 13s\n",
      "121:\tlearn: 0.3282118\ttotal: 9m 5s\tremaining: 28m 9s\n",
      "122:\tlearn: 0.3276763\ttotal: 9m 9s\tremaining: 28m 4s\n",
      "123:\tlearn: 0.3270021\ttotal: 9m 13s\tremaining: 27m 59s\n",
      "124:\tlearn: 0.3262204\ttotal: 9m 18s\tremaining: 27m 54s\n",
      "125:\tlearn: 0.3254663\ttotal: 9m 22s\tremaining: 27m 49s\n",
      "126:\tlearn: 0.3248452\ttotal: 9m 26s\tremaining: 27m 45s\n",
      "127:\tlearn: 0.3242188\ttotal: 9m 31s\tremaining: 27m 40s\n",
      "128:\tlearn: 0.3236973\ttotal: 9m 35s\tremaining: 27m 36s\n",
      "129:\tlearn: 0.3229032\ttotal: 9m 40s\tremaining: 27m 31s\n",
      "130:\tlearn: 0.3223604\ttotal: 9m 44s\tremaining: 27m 27s\n",
      "131:\tlearn: 0.3218653\ttotal: 9m 49s\tremaining: 27m 22s\n",
      "132:\tlearn: 0.3213414\ttotal: 9m 53s\tremaining: 27m 18s\n",
      "133:\tlearn: 0.3207954\ttotal: 9m 58s\tremaining: 27m 13s\n",
      "134:\tlearn: 0.3201504\ttotal: 10m 2s\tremaining: 27m 9s\n",
      "135:\tlearn: 0.3196432\ttotal: 10m 6s\tremaining: 27m 4s\n",
      "136:\tlearn: 0.3190703\ttotal: 10m 11s\tremaining: 26m 59s\n",
      "137:\tlearn: 0.3184347\ttotal: 10m 15s\tremaining: 26m 55s\n",
      "138:\tlearn: 0.3179380\ttotal: 10m 20s\tremaining: 26m 51s\n",
      "139:\tlearn: 0.3174505\ttotal: 10m 24s\tremaining: 26m 46s\n",
      "140:\tlearn: 0.3166411\ttotal: 10m 29s\tremaining: 26m 41s\n",
      "141:\tlearn: 0.3161313\ttotal: 10m 33s\tremaining: 26m 37s\n",
      "142:\tlearn: 0.3156089\ttotal: 10m 37s\tremaining: 26m 32s\n",
      "143:\tlearn: 0.3150638\ttotal: 10m 42s\tremaining: 26m 27s\n",
      "144:\tlearn: 0.3144411\ttotal: 10m 46s\tremaining: 26m 23s\n",
      "145:\tlearn: 0.3127768\ttotal: 10m 51s\tremaining: 26m 18s\n",
      "146:\tlearn: 0.3122826\ttotal: 10m 55s\tremaining: 26m 14s\n",
      "147:\tlearn: 0.3117041\ttotal: 11m\tremaining: 26m 10s\n",
      "148:\tlearn: 0.3112154\ttotal: 11m 4s\tremaining: 26m 6s\n",
      "149:\tlearn: 0.3106522\ttotal: 11m 9s\tremaining: 26m 1s\n",
      "150:\tlearn: 0.3099601\ttotal: 11m 13s\tremaining: 25m 57s\n",
      "151:\tlearn: 0.3093760\ttotal: 11m 18s\tremaining: 25m 53s\n",
      "152:\tlearn: 0.3088869\ttotal: 11m 22s\tremaining: 25m 48s\n",
      "153:\tlearn: 0.3084331\ttotal: 11m 27s\tremaining: 25m 44s\n",
      "154:\tlearn: 0.3080096\ttotal: 11m 31s\tremaining: 25m 39s\n",
      "155:\tlearn: 0.3075424\ttotal: 11m 36s\tremaining: 25m 34s\n",
      "156:\tlearn: 0.3070930\ttotal: 11m 40s\tremaining: 25m 30s\n",
      "157:\tlearn: 0.3065899\ttotal: 11m 44s\tremaining: 25m 25s\n",
      "158:\tlearn: 0.3060517\ttotal: 11m 49s\tremaining: 25m 20s\n",
      "159:\tlearn: 0.3052054\ttotal: 11m 53s\tremaining: 25m 16s\n",
      "160:\tlearn: 0.3047572\ttotal: 11m 57s\tremaining: 25m 11s\n",
      "161:\tlearn: 0.3042900\ttotal: 12m 2s\tremaining: 25m 7s\n",
      "162:\tlearn: 0.3038299\ttotal: 12m 6s\tremaining: 25m 2s\n",
      "163:\tlearn: 0.3033715\ttotal: 12m 11s\tremaining: 24m 58s\n",
      "164:\tlearn: 0.3029123\ttotal: 12m 15s\tremaining: 24m 53s\n",
      "165:\tlearn: 0.3022433\ttotal: 12m 20s\tremaining: 24m 49s\n",
      "166:\tlearn: 0.3018019\ttotal: 12m 24s\tremaining: 24m 44s\n",
      "167:\tlearn: 0.3013999\ttotal: 12m 29s\tremaining: 24m 40s\n",
      "168:\tlearn: 0.3007254\ttotal: 12m 33s\tremaining: 24m 35s\n",
      "169:\tlearn: 0.3002995\ttotal: 12m 37s\tremaining: 24m 31s\n",
      "170:\tlearn: 0.2999006\ttotal: 12m 42s\tremaining: 24m 26s\n",
      "171:\tlearn: 0.2995076\ttotal: 12m 46s\tremaining: 24m 22s\n",
      "172:\tlearn: 0.2985258\ttotal: 12m 51s\tremaining: 24m 17s\n",
      "173:\tlearn: 0.2978916\ttotal: 12m 56s\tremaining: 24m 13s\n",
      "174:\tlearn: 0.2974337\ttotal: 13m\tremaining: 24m 9s\n",
      "175:\tlearn: 0.2968793\ttotal: 13m 5s\tremaining: 24m 5s\n",
      "176:\tlearn: 0.2965070\ttotal: 13m 9s\tremaining: 24m\n",
      "177:\tlearn: 0.2961442\ttotal: 13m 13s\tremaining: 23m 55s\n",
      "178:\tlearn: 0.2956677\ttotal: 13m 18s\tremaining: 23m 51s\n",
      "179:\tlearn: 0.2948749\ttotal: 13m 22s\tremaining: 23m 47s\n",
      "180:\tlearn: 0.2945631\ttotal: 13m 27s\tremaining: 23m 42s\n",
      "181:\tlearn: 0.2941643\ttotal: 13m 31s\tremaining: 23m 37s\n",
      "182:\tlearn: 0.2936662\ttotal: 13m 36s\tremaining: 23m 33s\n",
      "183:\tlearn: 0.2932545\ttotal: 13m 40s\tremaining: 23m 29s\n",
      "184:\tlearn: 0.2928918\ttotal: 13m 44s\tremaining: 23m 24s\n",
      "185:\tlearn: 0.2924832\ttotal: 13m 49s\tremaining: 23m 19s\n",
      "186:\tlearn: 0.2920683\ttotal: 13m 53s\tremaining: 23m 15s\n",
      "187:\tlearn: 0.2915748\ttotal: 13m 58s\tremaining: 23m 10s\n",
      "188:\tlearn: 0.2912290\ttotal: 14m 2s\tremaining: 23m 6s\n",
      "189:\tlearn: 0.2906538\ttotal: 14m 6s\tremaining: 23m 1s\n",
      "190:\tlearn: 0.2901771\ttotal: 14m 11s\tremaining: 22m 57s\n",
      "191:\tlearn: 0.2898520\ttotal: 14m 15s\tremaining: 22m 52s\n",
      "192:\tlearn: 0.2894352\ttotal: 14m 20s\tremaining: 22m 48s\n",
      "193:\tlearn: 0.2891038\ttotal: 14m 24s\tremaining: 22m 43s\n",
      "194:\tlearn: 0.2887783\ttotal: 14m 29s\tremaining: 22m 39s\n",
      "195:\tlearn: 0.2882851\ttotal: 14m 33s\tremaining: 22m 34s\n",
      "196:\tlearn: 0.2879436\ttotal: 14m 37s\tremaining: 22m 30s\n",
      "197:\tlearn: 0.2875331\ttotal: 14m 42s\tremaining: 22m 25s\n",
      "198:\tlearn: 0.2872058\ttotal: 14m 46s\tremaining: 22m 21s\n",
      "199:\tlearn: 0.2868183\ttotal: 14m 51s\tremaining: 22m 16s\n",
      "200:\tlearn: 0.2863750\ttotal: 14m 55s\tremaining: 22m 12s\n",
      "201:\tlearn: 0.2859843\ttotal: 15m\tremaining: 22m 8s\n",
      "202:\tlearn: 0.2855795\ttotal: 15m 4s\tremaining: 22m 3s\n",
      "203:\tlearn: 0.2851798\ttotal: 15m 9s\tremaining: 21m 59s\n",
      "204:\tlearn: 0.2848357\ttotal: 15m 13s\tremaining: 21m 54s\n",
      "205:\tlearn: 0.2845362\ttotal: 15m 17s\tremaining: 21m 49s\n",
      "206:\tlearn: 0.2841774\ttotal: 15m 22s\tremaining: 21m 45s\n",
      "207:\tlearn: 0.2837829\ttotal: 15m 26s\tremaining: 21m 40s\n",
      "208:\tlearn: 0.2833854\ttotal: 15m 31s\tremaining: 21m 36s\n",
      "209:\tlearn: 0.2829948\ttotal: 15m 35s\tremaining: 21m 32s\n",
      "210:\tlearn: 0.2827448\ttotal: 15m 39s\tremaining: 21m 27s\n",
      "211:\tlearn: 0.2823820\ttotal: 15m 44s\tremaining: 21m 22s\n",
      "212:\tlearn: 0.2813545\ttotal: 15m 48s\tremaining: 21m 18s\n",
      "213:\tlearn: 0.2808490\ttotal: 15m 53s\tremaining: 21m 14s\n",
      "214:\tlearn: 0.2805036\ttotal: 15m 57s\tremaining: 21m 9s\n",
      "215:\tlearn: 0.2802261\ttotal: 16m 2s\tremaining: 21m 5s\n",
      "216:\tlearn: 0.2798805\ttotal: 16m 6s\tremaining: 21m\n",
      "217:\tlearn: 0.2796230\ttotal: 16m 10s\tremaining: 20m 56s\n",
      "218:\tlearn: 0.2792718\ttotal: 16m 15s\tremaining: 20m 51s\n",
      "219:\tlearn: 0.2789208\ttotal: 16m 19s\tremaining: 20m 47s\n",
      "220:\tlearn: 0.2785874\ttotal: 16m 24s\tremaining: 20m 42s\n",
      "221:\tlearn: 0.2783219\ttotal: 16m 28s\tremaining: 20m 38s\n",
      "222:\tlearn: 0.2779838\ttotal: 16m 33s\tremaining: 20m 33s\n",
      "223:\tlearn: 0.2777375\ttotal: 16m 37s\tremaining: 20m 29s\n",
      "224:\tlearn: 0.2774888\ttotal: 16m 41s\tremaining: 20m 24s\n",
      "225:\tlearn: 0.2771197\ttotal: 16m 46s\tremaining: 20m 19s\n",
      "226:\tlearn: 0.2767725\ttotal: 16m 50s\tremaining: 20m 15s\n",
      "227:\tlearn: 0.2764114\ttotal: 16m 55s\tremaining: 20m 11s\n",
      "228:\tlearn: 0.2760886\ttotal: 16m 59s\tremaining: 20m 6s\n",
      "229:\tlearn: 0.2757242\ttotal: 17m 3s\tremaining: 20m 2s\n",
      "230:\tlearn: 0.2754316\ttotal: 17m 8s\tremaining: 19m 57s\n",
      "231:\tlearn: 0.2750254\ttotal: 17m 12s\tremaining: 19m 53s\n",
      "232:\tlearn: 0.2746931\ttotal: 17m 17s\tremaining: 19m 48s\n",
      "233:\tlearn: 0.2743447\ttotal: 17m 21s\tremaining: 19m 44s\n",
      "234:\tlearn: 0.2740568\ttotal: 17m 26s\tremaining: 19m 39s\n",
      "235:\tlearn: 0.2736932\ttotal: 17m 30s\tremaining: 19m 35s\n",
      "236:\tlearn: 0.2733209\ttotal: 17m 35s\tremaining: 19m 30s\n",
      "237:\tlearn: 0.2729884\ttotal: 17m 39s\tremaining: 19m 26s\n",
      "238:\tlearn: 0.2725951\ttotal: 17m 43s\tremaining: 19m 21s\n",
      "239:\tlearn: 0.2722899\ttotal: 17m 48s\tremaining: 19m 17s\n",
      "240:\tlearn: 0.2719787\ttotal: 17m 52s\tremaining: 19m 12s\n",
      "241:\tlearn: 0.2716931\ttotal: 17m 57s\tremaining: 19m 8s\n",
      "242:\tlearn: 0.2713925\ttotal: 18m 1s\tremaining: 19m 3s\n",
      "243:\tlearn: 0.2710890\ttotal: 18m 5s\tremaining: 18m 59s\n",
      "244:\tlearn: 0.2708076\ttotal: 18m 10s\tremaining: 18m 54s\n",
      "245:\tlearn: 0.2704871\ttotal: 18m 14s\tremaining: 18m 50s\n",
      "246:\tlearn: 0.2701719\ttotal: 18m 19s\tremaining: 18m 45s\n",
      "247:\tlearn: 0.2698788\ttotal: 18m 23s\tremaining: 18m 41s\n",
      "248:\tlearn: 0.2696665\ttotal: 18m 27s\tremaining: 18m 36s\n",
      "249:\tlearn: 0.2693916\ttotal: 18m 32s\tremaining: 18m 32s\n",
      "250:\tlearn: 0.2690540\ttotal: 18m 36s\tremaining: 18m 27s\n",
      "251:\tlearn: 0.2686780\ttotal: 18m 41s\tremaining: 18m 23s\n",
      "252:\tlearn: 0.2682858\ttotal: 18m 45s\tremaining: 18m 18s\n",
      "253:\tlearn: 0.2679713\ttotal: 18m 49s\tremaining: 18m 14s\n",
      "254:\tlearn: 0.2676452\ttotal: 18m 54s\tremaining: 18m 9s\n",
      "255:\tlearn: 0.2673726\ttotal: 18m 59s\tremaining: 18m 5s\n",
      "256:\tlearn: 0.2670258\ttotal: 19m 3s\tremaining: 18m 1s\n",
      "257:\tlearn: 0.2667397\ttotal: 19m 7s\tremaining: 17m 56s\n",
      "258:\tlearn: 0.2665385\ttotal: 19m 12s\tremaining: 17m 52s\n",
      "259:\tlearn: 0.2661054\ttotal: 19m 16s\tremaining: 17m 47s\n",
      "260:\tlearn: 0.2658107\ttotal: 19m 21s\tremaining: 17m 43s\n",
      "261:\tlearn: 0.2649510\ttotal: 19m 25s\tremaining: 17m 38s\n",
      "262:\tlearn: 0.2647107\ttotal: 19m 29s\tremaining: 17m 34s\n",
      "263:\tlearn: 0.2641010\ttotal: 19m 34s\tremaining: 17m 29s\n",
      "264:\tlearn: 0.2637762\ttotal: 19m 38s\tremaining: 17m 25s\n",
      "265:\tlearn: 0.2635784\ttotal: 19m 43s\tremaining: 17m 20s\n",
      "266:\tlearn: 0.2632485\ttotal: 19m 47s\tremaining: 17m 16s\n",
      "267:\tlearn: 0.2629828\ttotal: 19m 52s\tremaining: 17m 11s\n",
      "268:\tlearn: 0.2626931\ttotal: 19m 56s\tremaining: 17m 7s\n",
      "269:\tlearn: 0.2625117\ttotal: 20m\tremaining: 17m 2s\n",
      "270:\tlearn: 0.2622555\ttotal: 20m 5s\tremaining: 16m 58s\n",
      "271:\tlearn: 0.2620300\ttotal: 20m 9s\tremaining: 16m 53s\n",
      "272:\tlearn: 0.2617668\ttotal: 20m 14s\tremaining: 16m 49s\n",
      "273:\tlearn: 0.2614990\ttotal: 20m 18s\tremaining: 16m 44s\n",
      "274:\tlearn: 0.2611951\ttotal: 20m 22s\tremaining: 16m 40s\n",
      "275:\tlearn: 0.2608713\ttotal: 20m 27s\tremaining: 16m 36s\n",
      "276:\tlearn: 0.2606446\ttotal: 20m 31s\tremaining: 16m 31s\n",
      "277:\tlearn: 0.2603139\ttotal: 20m 36s\tremaining: 16m 27s\n",
      "278:\tlearn: 0.2600814\ttotal: 20m 40s\tremaining: 16m 22s\n",
      "279:\tlearn: 0.2597732\ttotal: 20m 45s\tremaining: 16m 18s\n",
      "280:\tlearn: 0.2595470\ttotal: 20m 49s\tremaining: 16m 13s\n",
      "281:\tlearn: 0.2592701\ttotal: 20m 53s\tremaining: 16m 9s\n",
      "282:\tlearn: 0.2590538\ttotal: 20m 58s\tremaining: 16m 4s\n",
      "283:\tlearn: 0.2588079\ttotal: 21m 2s\tremaining: 16m\n",
      "284:\tlearn: 0.2586536\ttotal: 21m 7s\tremaining: 15m 55s\n",
      "285:\tlearn: 0.2583969\ttotal: 21m 11s\tremaining: 15m 51s\n",
      "286:\tlearn: 0.2581725\ttotal: 21m 16s\tremaining: 15m 47s\n",
      "287:\tlearn: 0.2578938\ttotal: 21m 20s\tremaining: 15m 42s\n",
      "288:\tlearn: 0.2575757\ttotal: 21m 25s\tremaining: 15m 38s\n",
      "289:\tlearn: 0.2573327\ttotal: 21m 29s\tremaining: 15m 33s\n",
      "290:\tlearn: 0.2570166\ttotal: 21m 33s\tremaining: 15m 29s\n",
      "291:\tlearn: 0.2567848\ttotal: 21m 38s\tremaining: 15m 24s\n",
      "292:\tlearn: 0.2565083\ttotal: 21m 42s\tremaining: 15m 20s\n",
      "293:\tlearn: 0.2561100\ttotal: 21m 47s\tremaining: 15m 15s\n",
      "294:\tlearn: 0.2558843\ttotal: 21m 51s\tremaining: 15m 11s\n",
      "295:\tlearn: 0.2555832\ttotal: 21m 55s\tremaining: 15m 6s\n",
      "296:\tlearn: 0.2553102\ttotal: 22m\tremaining: 15m 2s\n",
      "297:\tlearn: 0.2550450\ttotal: 22m 4s\tremaining: 14m 57s\n",
      "298:\tlearn: 0.2547800\ttotal: 22m 9s\tremaining: 14m 53s\n",
      "299:\tlearn: 0.2544645\ttotal: 22m 13s\tremaining: 14m 49s\n",
      "300:\tlearn: 0.2542965\ttotal: 22m 17s\tremaining: 14m 44s\n",
      "301:\tlearn: 0.2540230\ttotal: 22m 22s\tremaining: 14m 40s\n",
      "302:\tlearn: 0.2538301\ttotal: 22m 26s\tremaining: 14m 35s\n",
      "303:\tlearn: 0.2536172\ttotal: 22m 31s\tremaining: 14m 31s\n",
      "304:\tlearn: 0.2532125\ttotal: 22m 35s\tremaining: 14m 26s\n",
      "305:\tlearn: 0.2530372\ttotal: 22m 39s\tremaining: 14m 22s\n",
      "306:\tlearn: 0.2527873\ttotal: 22m 44s\tremaining: 14m 17s\n",
      "307:\tlearn: 0.2524994\ttotal: 22m 48s\tremaining: 14m 13s\n",
      "308:\tlearn: 0.2522579\ttotal: 22m 53s\tremaining: 14m 8s\n",
      "309:\tlearn: 0.2520469\ttotal: 22m 57s\tremaining: 14m 4s\n",
      "310:\tlearn: 0.2517699\ttotal: 23m 2s\tremaining: 14m\n",
      "311:\tlearn: 0.2515961\ttotal: 23m 6s\tremaining: 13m 55s\n",
      "312:\tlearn: 0.2512957\ttotal: 23m 11s\tremaining: 13m 51s\n",
      "313:\tlearn: 0.2511391\ttotal: 23m 15s\tremaining: 13m 46s\n",
      "314:\tlearn: 0.2508998\ttotal: 23m 20s\tremaining: 13m 42s\n",
      "315:\tlearn: 0.2506870\ttotal: 23m 24s\tremaining: 13m 37s\n",
      "316:\tlearn: 0.2504203\ttotal: 23m 28s\tremaining: 13m 33s\n",
      "317:\tlearn: 0.2502173\ttotal: 23m 33s\tremaining: 13m 28s\n",
      "318:\tlearn: 0.2500499\ttotal: 23m 37s\tremaining: 13m 24s\n",
      "319:\tlearn: 0.2498268\ttotal: 23m 42s\tremaining: 13m 19s\n",
      "320:\tlearn: 0.2496854\ttotal: 23m 46s\tremaining: 13m 15s\n",
      "321:\tlearn: 0.2495394\ttotal: 23m 50s\tremaining: 13m 10s\n",
      "322:\tlearn: 0.2492773\ttotal: 23m 55s\tremaining: 13m 6s\n",
      "323:\tlearn: 0.2491390\ttotal: 23m 59s\tremaining: 13m 1s\n",
      "324:\tlearn: 0.2489164\ttotal: 24m 3s\tremaining: 12m 57s\n",
      "325:\tlearn: 0.2487008\ttotal: 24m 8s\tremaining: 12m 53s\n",
      "326:\tlearn: 0.2484270\ttotal: 24m 12s\tremaining: 12m 48s\n",
      "327:\tlearn: 0.2481088\ttotal: 24m 17s\tremaining: 12m 44s\n",
      "328:\tlearn: 0.2479335\ttotal: 24m 21s\tremaining: 12m 39s\n",
      "329:\tlearn: 0.2477186\ttotal: 24m 25s\tremaining: 12m 35s\n",
      "330:\tlearn: 0.2473870\ttotal: 24m 30s\tremaining: 12m 30s\n",
      "331:\tlearn: 0.2471405\ttotal: 24m 35s\tremaining: 12m 26s\n",
      "332:\tlearn: 0.2468990\ttotal: 24m 39s\tremaining: 12m 21s\n",
      "333:\tlearn: 0.2466963\ttotal: 24m 43s\tremaining: 12m 17s\n",
      "334:\tlearn: 0.2465270\ttotal: 24m 48s\tremaining: 12m 12s\n",
      "335:\tlearn: 0.2462909\ttotal: 24m 52s\tremaining: 12m 8s\n",
      "336:\tlearn: 0.2460015\ttotal: 24m 57s\tremaining: 12m 4s\n",
      "337:\tlearn: 0.2455391\ttotal: 25m 1s\tremaining: 11m 59s\n",
      "338:\tlearn: 0.2453862\ttotal: 25m 5s\tremaining: 11m 55s\n",
      "339:\tlearn: 0.2452511\ttotal: 25m 10s\tremaining: 11m 50s\n",
      "340:\tlearn: 0.2449796\ttotal: 25m 14s\tremaining: 11m 46s\n",
      "341:\tlearn: 0.2447708\ttotal: 25m 19s\tremaining: 11m 41s\n",
      "342:\tlearn: 0.2445426\ttotal: 25m 23s\tremaining: 11m 37s\n",
      "343:\tlearn: 0.2443139\ttotal: 25m 28s\tremaining: 11m 32s\n",
      "344:\tlearn: 0.2441380\ttotal: 25m 32s\tremaining: 11m 28s\n",
      "345:\tlearn: 0.2439580\ttotal: 25m 36s\tremaining: 11m 24s\n",
      "346:\tlearn: 0.2438266\ttotal: 25m 41s\tremaining: 11m 19s\n",
      "347:\tlearn: 0.2435442\ttotal: 25m 45s\tremaining: 11m 15s\n",
      "348:\tlearn: 0.2432659\ttotal: 25m 50s\tremaining: 11m 10s\n",
      "349:\tlearn: 0.2429293\ttotal: 25m 54s\tremaining: 11m 6s\n",
      "350:\tlearn: 0.2426864\ttotal: 25m 59s\tremaining: 11m 1s\n",
      "351:\tlearn: 0.2425075\ttotal: 26m 3s\tremaining: 10m 57s\n",
      "352:\tlearn: 0.2422888\ttotal: 26m 8s\tremaining: 10m 52s\n",
      "353:\tlearn: 0.2421204\ttotal: 26m 12s\tremaining: 10m 48s\n",
      "354:\tlearn: 0.2418337\ttotal: 26m 16s\tremaining: 10m 44s\n",
      "355:\tlearn: 0.2416217\ttotal: 26m 21s\tremaining: 10m 39s\n",
      "356:\tlearn: 0.2414477\ttotal: 26m 25s\tremaining: 10m 35s\n",
      "357:\tlearn: 0.2412053\ttotal: 26m 30s\tremaining: 10m 30s\n",
      "358:\tlearn: 0.2410913\ttotal: 26m 34s\tremaining: 10m 26s\n",
      "359:\tlearn: 0.2409336\ttotal: 26m 39s\tremaining: 10m 21s\n",
      "360:\tlearn: 0.2407364\ttotal: 26m 43s\tremaining: 10m 17s\n",
      "361:\tlearn: 0.2404808\ttotal: 26m 47s\tremaining: 10m 12s\n",
      "362:\tlearn: 0.2402861\ttotal: 26m 52s\tremaining: 10m 8s\n",
      "363:\tlearn: 0.2401244\ttotal: 26m 56s\tremaining: 10m 4s\n",
      "364:\tlearn: 0.2399193\ttotal: 27m 1s\tremaining: 9m 59s\n",
      "365:\tlearn: 0.2397693\ttotal: 27m 5s\tremaining: 9m 55s\n",
      "366:\tlearn: 0.2396219\ttotal: 27m 10s\tremaining: 9m 50s\n",
      "367:\tlearn: 0.2393618\ttotal: 27m 14s\tremaining: 9m 46s\n",
      "368:\tlearn: 0.2391926\ttotal: 27m 18s\tremaining: 9m 41s\n",
      "369:\tlearn: 0.2389776\ttotal: 27m 23s\tremaining: 9m 37s\n",
      "370:\tlearn: 0.2387278\ttotal: 27m 27s\tremaining: 9m 32s\n",
      "371:\tlearn: 0.2385737\ttotal: 27m 32s\tremaining: 9m 28s\n",
      "372:\tlearn: 0.2384603\ttotal: 27m 36s\tremaining: 9m 23s\n",
      "373:\tlearn: 0.2382686\ttotal: 27m 40s\tremaining: 9m 19s\n",
      "374:\tlearn: 0.2380692\ttotal: 27m 45s\tremaining: 9m 15s\n",
      "375:\tlearn: 0.2378759\ttotal: 27m 49s\tremaining: 9m 10s\n",
      "376:\tlearn: 0.2376600\ttotal: 27m 54s\tremaining: 9m 6s\n",
      "377:\tlearn: 0.2374811\ttotal: 27m 58s\tremaining: 9m 1s\n",
      "378:\tlearn: 0.2373782\ttotal: 28m 2s\tremaining: 8m 57s\n",
      "379:\tlearn: 0.2372160\ttotal: 28m 7s\tremaining: 8m 52s\n",
      "380:\tlearn: 0.2369363\ttotal: 28m 11s\tremaining: 8m 48s\n",
      "381:\tlearn: 0.2367386\ttotal: 28m 16s\tremaining: 8m 43s\n",
      "382:\tlearn: 0.2365157\ttotal: 28m 20s\tremaining: 8m 39s\n",
      "383:\tlearn: 0.2363174\ttotal: 28m 24s\tremaining: 8m 35s\n",
      "384:\tlearn: 0.2361162\ttotal: 28m 29s\tremaining: 8m 30s\n",
      "385:\tlearn: 0.2359298\ttotal: 28m 33s\tremaining: 8m 26s\n",
      "386:\tlearn: 0.2356949\ttotal: 28m 38s\tremaining: 8m 21s\n",
      "387:\tlearn: 0.2355704\ttotal: 28m 42s\tremaining: 8m 17s\n",
      "388:\tlearn: 0.2352959\ttotal: 28m 47s\tremaining: 8m 12s\n",
      "389:\tlearn: 0.2350666\ttotal: 28m 51s\tremaining: 8m 8s\n",
      "390:\tlearn: 0.2349366\ttotal: 28m 56s\tremaining: 8m 3s\n",
      "391:\tlearn: 0.2347546\ttotal: 29m\tremaining: 7m 59s\n",
      "392:\tlearn: 0.2346195\ttotal: 29m 5s\tremaining: 7m 55s\n",
      "393:\tlearn: 0.2344329\ttotal: 29m 9s\tremaining: 7m 50s\n",
      "394:\tlearn: 0.2341271\ttotal: 29m 13s\tremaining: 7m 46s\n",
      "395:\tlearn: 0.2339254\ttotal: 29m 18s\tremaining: 7m 41s\n",
      "396:\tlearn: 0.2335779\ttotal: 29m 22s\tremaining: 7m 37s\n",
      "397:\tlearn: 0.2333583\ttotal: 29m 27s\tremaining: 7m 32s\n",
      "398:\tlearn: 0.2331277\ttotal: 29m 31s\tremaining: 7m 28s\n",
      "399:\tlearn: 0.2330068\ttotal: 29m 36s\tremaining: 7m 24s\n",
      "400:\tlearn: 0.2329100\ttotal: 29m 40s\tremaining: 7m 19s\n",
      "401:\tlearn: 0.2327403\ttotal: 29m 44s\tremaining: 7m 15s\n",
      "402:\tlearn: 0.2325715\ttotal: 29m 49s\tremaining: 7m 10s\n",
      "403:\tlearn: 0.2321084\ttotal: 29m 53s\tremaining: 7m 6s\n",
      "404:\tlearn: 0.2320038\ttotal: 29m 58s\tremaining: 7m 1s\n",
      "405:\tlearn: 0.2316965\ttotal: 30m 2s\tremaining: 6m 57s\n",
      "406:\tlearn: 0.2314035\ttotal: 30m 7s\tremaining: 6m 52s\n",
      "407:\tlearn: 0.2312634\ttotal: 30m 11s\tremaining: 6m 48s\n",
      "408:\tlearn: 0.2311008\ttotal: 30m 16s\tremaining: 6m 44s\n",
      "409:\tlearn: 0.2310100\ttotal: 30m 20s\tremaining: 6m 39s\n",
      "410:\tlearn: 0.2308803\ttotal: 30m 24s\tremaining: 6m 35s\n",
      "411:\tlearn: 0.2306458\ttotal: 30m 29s\tremaining: 6m 30s\n",
      "412:\tlearn: 0.2305210\ttotal: 30m 33s\tremaining: 6m 26s\n",
      "413:\tlearn: 0.2303394\ttotal: 30m 38s\tremaining: 6m 21s\n",
      "414:\tlearn: 0.2302276\ttotal: 30m 42s\tremaining: 6m 17s\n",
      "415:\tlearn: 0.2299923\ttotal: 30m 47s\tremaining: 6m 12s\n",
      "416:\tlearn: 0.2298230\ttotal: 30m 51s\tremaining: 6m 8s\n",
      "417:\tlearn: 0.2295620\ttotal: 30m 56s\tremaining: 6m 4s\n",
      "418:\tlearn: 0.2291983\ttotal: 31m\tremaining: 5m 59s\n",
      "419:\tlearn: 0.2290262\ttotal: 31m 4s\tremaining: 5m 55s\n",
      "420:\tlearn: 0.2288240\ttotal: 31m 9s\tremaining: 5m 50s\n",
      "421:\tlearn: 0.2286454\ttotal: 31m 13s\tremaining: 5m 46s\n",
      "422:\tlearn: 0.2284687\ttotal: 31m 18s\tremaining: 5m 41s\n",
      "423:\tlearn: 0.2282327\ttotal: 31m 22s\tremaining: 5m 37s\n",
      "424:\tlearn: 0.2280638\ttotal: 31m 27s\tremaining: 5m 33s\n",
      "425:\tlearn: 0.2279207\ttotal: 31m 31s\tremaining: 5m 28s\n",
      "426:\tlearn: 0.2278305\ttotal: 31m 35s\tremaining: 5m 24s\n",
      "427:\tlearn: 0.2277234\ttotal: 31m 40s\tremaining: 5m 19s\n",
      "428:\tlearn: 0.2275626\ttotal: 31m 44s\tremaining: 5m 15s\n",
      "429:\tlearn: 0.2273458\ttotal: 31m 48s\tremaining: 5m 10s\n",
      "430:\tlearn: 0.2271842\ttotal: 31m 53s\tremaining: 5m 6s\n",
      "431:\tlearn: 0.2270119\ttotal: 31m 57s\tremaining: 5m 1s\n",
      "432:\tlearn: 0.2269045\ttotal: 32m 2s\tremaining: 4m 57s\n",
      "433:\tlearn: 0.2267707\ttotal: 32m 6s\tremaining: 4m 52s\n",
      "434:\tlearn: 0.2265517\ttotal: 32m 11s\tremaining: 4m 48s\n",
      "435:\tlearn: 0.2263439\ttotal: 32m 15s\tremaining: 4m 44s\n",
      "436:\tlearn: 0.2261891\ttotal: 32m 20s\tremaining: 4m 39s\n",
      "437:\tlearn: 0.2261037\ttotal: 32m 24s\tremaining: 4m 35s\n",
      "438:\tlearn: 0.2259484\ttotal: 32m 29s\tremaining: 4m 30s\n",
      "439:\tlearn: 0.2257210\ttotal: 32m 33s\tremaining: 4m 26s\n",
      "440:\tlearn: 0.2255268\ttotal: 32m 37s\tremaining: 4m 21s\n",
      "441:\tlearn: 0.2253674\ttotal: 32m 42s\tremaining: 4m 17s\n",
      "442:\tlearn: 0.2251710\ttotal: 32m 46s\tremaining: 4m 13s\n",
      "443:\tlearn: 0.2248752\ttotal: 32m 51s\tremaining: 4m 8s\n",
      "444:\tlearn: 0.2247247\ttotal: 32m 55s\tremaining: 4m 4s\n",
      "445:\tlearn: 0.2245066\ttotal: 33m\tremaining: 3m 59s\n",
      "446:\tlearn: 0.2242895\ttotal: 33m 4s\tremaining: 3m 55s\n",
      "447:\tlearn: 0.2240701\ttotal: 33m 8s\tremaining: 3m 50s\n",
      "448:\tlearn: 0.2239844\ttotal: 33m 13s\tremaining: 3m 46s\n",
      "449:\tlearn: 0.2238834\ttotal: 33m 17s\tremaining: 3m 41s\n",
      "450:\tlearn: 0.2237138\ttotal: 33m 22s\tremaining: 3m 37s\n",
      "451:\tlearn: 0.2236317\ttotal: 33m 26s\tremaining: 3m 33s\n",
      "452:\tlearn: 0.2234621\ttotal: 33m 30s\tremaining: 3m 28s\n",
      "453:\tlearn: 0.2233620\ttotal: 33m 35s\tremaining: 3m 24s\n",
      "454:\tlearn: 0.2232073\ttotal: 33m 39s\tremaining: 3m 19s\n",
      "455:\tlearn: 0.2230704\ttotal: 33m 44s\tremaining: 3m 15s\n",
      "456:\tlearn: 0.2229885\ttotal: 33m 48s\tremaining: 3m 10s\n",
      "457:\tlearn: 0.2227182\ttotal: 33m 52s\tremaining: 3m 6s\n",
      "458:\tlearn: 0.2225473\ttotal: 33m 57s\tremaining: 3m 1s\n",
      "459:\tlearn: 0.2223344\ttotal: 34m 1s\tremaining: 2m 57s\n",
      "460:\tlearn: 0.2221505\ttotal: 34m 6s\tremaining: 2m 53s\n",
      "461:\tlearn: 0.2219669\ttotal: 34m 10s\tremaining: 2m 48s\n",
      "462:\tlearn: 0.2218495\ttotal: 34m 15s\tremaining: 2m 44s\n",
      "463:\tlearn: 0.2216790\ttotal: 34m 19s\tremaining: 2m 39s\n",
      "464:\tlearn: 0.2214790\ttotal: 34m 24s\tremaining: 2m 35s\n",
      "465:\tlearn: 0.2213810\ttotal: 34m 28s\tremaining: 2m 30s\n",
      "466:\tlearn: 0.2212149\ttotal: 34m 32s\tremaining: 2m 26s\n",
      "467:\tlearn: 0.2211354\ttotal: 34m 37s\tremaining: 2m 22s\n",
      "468:\tlearn: 0.2209884\ttotal: 34m 41s\tremaining: 2m 17s\n",
      "469:\tlearn: 0.2208387\ttotal: 34m 46s\tremaining: 2m 13s\n",
      "470:\tlearn: 0.2206541\ttotal: 34m 50s\tremaining: 2m 8s\n",
      "471:\tlearn: 0.2205779\ttotal: 34m 55s\tremaining: 2m 4s\n",
      "472:\tlearn: 0.2204831\ttotal: 34m 59s\tremaining: 1m 59s\n",
      "473:\tlearn: 0.2202654\ttotal: 35m 4s\tremaining: 1m 55s\n",
      "474:\tlearn: 0.2200827\ttotal: 35m 8s\tremaining: 1m 50s\n",
      "475:\tlearn: 0.2198990\ttotal: 35m 12s\tremaining: 1m 46s\n",
      "476:\tlearn: 0.2196641\ttotal: 35m 17s\tremaining: 1m 42s\n",
      "477:\tlearn: 0.2194953\ttotal: 35m 21s\tremaining: 1m 37s\n",
      "478:\tlearn: 0.2193209\ttotal: 35m 26s\tremaining: 1m 33s\n",
      "479:\tlearn: 0.2191378\ttotal: 35m 30s\tremaining: 1m 28s\n",
      "480:\tlearn: 0.2190183\ttotal: 35m 34s\tremaining: 1m 24s\n",
      "481:\tlearn: 0.2189392\ttotal: 35m 39s\tremaining: 1m 19s\n",
      "482:\tlearn: 0.2187416\ttotal: 35m 43s\tremaining: 1m 15s\n",
      "483:\tlearn: 0.2185867\ttotal: 35m 48s\tremaining: 1m 11s\n",
      "484:\tlearn: 0.2184214\ttotal: 35m 52s\tremaining: 1m 6s\n",
      "485:\tlearn: 0.2182451\ttotal: 35m 57s\tremaining: 1m 2s\n",
      "486:\tlearn: 0.2181679\ttotal: 36m 1s\tremaining: 57.7s\n",
      "487:\tlearn: 0.2179610\ttotal: 36m 6s\tremaining: 53.3s\n",
      "488:\tlearn: 0.2178876\ttotal: 36m 10s\tremaining: 48.8s\n",
      "489:\tlearn: 0.2178134\ttotal: 36m 14s\tremaining: 44.4s\n",
      "490:\tlearn: 0.2176219\ttotal: 36m 19s\tremaining: 39.9s\n",
      "491:\tlearn: 0.2175080\ttotal: 36m 23s\tremaining: 35.5s\n",
      "492:\tlearn: 0.2172921\ttotal: 36m 27s\tremaining: 31.1s\n",
      "493:\tlearn: 0.2170831\ttotal: 36m 32s\tremaining: 26.6s\n",
      "494:\tlearn: 0.2168573\ttotal: 36m 36s\tremaining: 22.2s\n",
      "495:\tlearn: 0.2166830\ttotal: 36m 41s\tremaining: 17.8s\n",
      "496:\tlearn: 0.2165006\ttotal: 36m 45s\tremaining: 13.3s\n",
      "497:\tlearn: 0.2163379\ttotal: 36m 50s\tremaining: 8.88s\n",
      "498:\tlearn: 0.2161867\ttotal: 36m 54s\tremaining: 4.44s\n",
      "499:\tlearn: 0.2160493\ttotal: 36m 59s\tremaining: 0us\n",
      "CPU times: user 37min 33s, sys: 41.5 s, total: 38min 14s\n",
      "Wall time: 38min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f01c5f21190>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "CatBoost_clf.fit(train_tf_idf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.750\n",
      "CPU times: user 1.46 s, sys: 355 ms, total: 1.82 s\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring(CatBoost_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим модель градиентного бустинга LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(n_jobs=-1, random_state=17, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_params = {'n_estimators': [500],\n",
    "                   'learning_rate': [0.1, 0.3, 0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgbm_clf_grid = GridSearchCV(lgbm_clf, lgbm_clf_params, scoring='f1')\n",
    "lgbm_clf_grid.fit(train_tf_idf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best parameters: ', lgbm_clf_grid.best_params_)\n",
    "print('best scores: ', lgbm_clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scoring(lgbm_clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBERT представляет собой уменьшенную версию BERT'а. Она быстрее и легче своего старшего собрата, но при этом вполне сравнима в результативности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим предобученную модель DistilBERT и токенизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (\n",
    "    ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=df['text'].shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель DistilBERT принимает максимальное количество токенов в тексте по умолчанию равное 512. Посчитаем длины текстов с токенами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sentences = [len(i) for i in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sentences = pd.Series(len_sentences)\n",
    "len_sentences.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видем что есть аномально длинные. Ограничим тексты максимальной длиной токенов 75% квантилем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for i in notebook.tqdm(range(len(tokenized))):\n",
    "    if len(tokenized[i]) <= len_sentences.quantile(.75):\n",
    "        indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.query('index in @indexes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датафрейм на 2 части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_train, filtered_df_test = train_test_split(filtered_df, random_state=17, test_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_train.shape, filtered_df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы сбалансировать метки целевого признака в обучающей выборке, воспользуемся техникой downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Уменьшение выборки downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef  = round((len(filtered_df_train[filtered_df_train['toxic'] == 1]) / \n",
    "               len(filtered_df_train[filtered_df_train['toxic'] == 0])), 3)\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию downsample(features, target, fraction) для формирования сблалансированной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=17)] +\n",
    "                                     [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=17)] +\n",
    "                                     [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled,\n",
    "                                                      random_state=17)\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(filtered_df_train['text'], filtered_df_train['toxic'], coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем размеры получившихся выборок и распределение целевого признака в обучающей выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled.shape, target_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.countplot(target_downsampled, palette='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объеденим снова в один ДатаФрейм обучающую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled = pd.DataFrame(features_downsampled).reset_index(drop=True)\n",
    "target_downsampled = pd.DataFrame(target_downsampled).reset_index(drop=True)\n",
    "filtered_df_train = features_downsampled.join(target_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_train.shape, filtered_df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эмбеддинги модель BERT создаёт батчами. Чтобы хватило оперативной памяти, сделаем размер батча небольшим (100). Обучающую выборку сделаем кратной размеру батча."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_train = filtered_df_train[:25900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним токенезацию новых текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenized_train = filtered_df_train['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=filtered_df_train['text'].shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenized_test = filtered_df_test['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=filtered_df_test['text'].shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными. Только при таком условии будет работать модель BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(tokenized):\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    return padded\n",
    "\n",
    "padded_train = padding(tokenized_train)\n",
    "padded_test = padding(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(padded_train).shape, np.array(padded_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь поясним модели, что нули не несут значимой информации. Это нужно для компоненты модели, которая называется «внимание». Отбросим эти токены и «создадим маску» для действительно важных токенов, то есть укажем нулевые и не нулевые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask_train = np.where(padded_train != 0, 1, 0)\n",
    "attention_mask_test = np.where(padded_test != 0, 1, 0)\n",
    "attention_mask_train.shape, attention_mask_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделав цикл по батчам, отобразим прогресс функцией notebook()\n",
    "Преобразуем данные в формат тензоров. Тип данных LongTensor хранит числа в «длинном формате», то есть выделяет на каждое число 64 бита.\n",
    "Чтобы получить эмбеддинги для батча, передадим модели данные и маску\n",
    "Для ускорения вычисления функцией no_grad() в библиотеке torch укажем, что градиенты не нужны: модель BERT обучать не будем.\n",
    "Из полученного тензора извлечём нужные элементы batch_embeddings[0][:,0,:].numpy() и добавим в список всех эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedings(padded, attention_mask):\n",
    "    batch_size = 100\n",
    "    embeddings = []\n",
    "    for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "            batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "            attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "            embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    features = np.concatenate(embeddings)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = embedings(padded_train, attention_mask_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = embedings(padded_test, attention_mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = filtered_df_train['toxic']\n",
    "labels_test = filtered_df_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_BERT(fitted_model):\n",
    "    test_pred = fitted_model.predict(features_test)\n",
    "    test_f1 = f1_score(labels_test, test_pred)\n",
    "    \n",
    "    print('F1 на тестовой выборке: {:.3f}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим Логистическую регрессию LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_params = {'C': np.linspace(0.0001, 100, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log_reg_grid = GridSearchCV(log_reg, log_reg_params, scoring='f1')\n",
    "log_reg_grid.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best parameters: ', log_reg_grid.best_params_)\n",
    "print('best scores: ', log_reg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scoring_BERT(log_reg_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель градиентного бустинга XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(random_state=17, n_jobs=-1, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_BERT(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель градиентного бустинга CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoost_clf = CatBoostClassifier(random_state=17, iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "CatBoost_clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_BERT(CatBoost_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель градиентного бустинга LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(n_jobs=-1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_params = {'n_estimators': [500],\n",
    "                   'learning_rate': [0.1, 0.3, 0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgbm_clf_grid = GridSearchCV(lgbm_clf, lgbm_clf_params, scoring='f1')\n",
    "lgbm_clf_grid.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best parameters: ', lgbm_clf_grid.best_params_)\n",
    "print('best scores: ', lgbm_clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scoring_BERT(lgbm_clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка модели на вменяемость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы получить «случайные» результаты, воспользуемся DummyClassifier. Полученные им результаты абсолютно случайные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dummy_clf, features_train, labels_train, scoring='f1')\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_BERT(dummy_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что в среднем модель предсказывает 50/50. Что гораздо хуже рассмотренных выше моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "В процессе обучения моделей обнаружили по TF-IDF:\n",
    "\n",
    "Почти все модели показали значение f1 в районе 0.76.\n",
    "Лучшей по метрики f1 является Логистическая XGBClassifier\n",
    "Лучшей по времени обучения Логистическая Регрессия\n",
    "\n",
    "В процессе обучения моделей по BERT:\n",
    "\n",
    "Почти все модели показали значение f1 в районе 0.67\n",
    "Лучшей также является Логистическая Регрессия c результатом 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы  <a id='step1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем все модели на качество предсказания, скорость обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем все данные в таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Модель':['LogisticRegression', 'XGBClassifier', 'CatBoostClassifier', 'LGBMClassifier'], \n",
    "        'Скорость обучения':['Очень высокая', 'Высокая', 'Высокая', 'Очень высокая'],\n",
    "        'Качество предсказания по TF-IDF': [0.761, 0.775, 0.75, 0.76],\n",
    "        'Качество предсказания по BERT': [ 0.69, 0.676, 0.675, 0.674]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Скорость обучения</th>\n",
       "      <th>Качество предсказания по TF-IDF</th>\n",
       "      <th>Качество предсказания по BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Очень высокая</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Высокая</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>Высокая</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>Очень высокая</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель Скорость обучения  Качество предсказания по TF-IDF  \\\n",
       "0  LogisticRegression     Очень высокая                            0.761   \n",
       "1       XGBClassifier           Высокая                            0.775   \n",
       "2  CatBoostClassifier           Высокая                            0.750   \n",
       "3      LGBMClassifier     Очень высокая                            0.760   \n",
       "\n",
       "   Качество предсказания по BERT  \n",
       "0                          0.690  \n",
       "1                          0.676  \n",
       "2                          0.675  \n",
       "3                          0.674  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "По результатам исследований моделей для поставленной задачи наиболее оптимальными являются:\n",
    "\n",
    "**LogisticRegression**\n",
    "\n",
    "LogisticRegression - базовая модель, показывает хорошие показатели метрик и скорости обучения и предсказания, очень проста в настройке и не требует особой настройки гиперпараметров по сетке. Очень хорошо работает с предобработанными данными (после TF-IDF).\n",
    "В целом все модели дают хорошие показатели метрики, но по скорости обучения отличаются.\n",
    "\n",
    "Представление текста в векторную форму через BERT проще, поскольку не требует предварительной лемматизации, но есть свои особенности в настройки модели.\n",
    "\n",
    "Для данной задачи лучшая для заказчика в плане качества предсказания, скорости предсказания, время обучения - LogisticRegression.\n",
    "Она лучше всего работает с предобработанными данными и имеет самую высокую скорость обучения, как все линейные модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
